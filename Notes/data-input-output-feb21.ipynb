{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Input and Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To this point, we have primarily entered the information into our various data structures manually. For most applications, we will load our data into an appropriate data structure, and potentially output our processed and/or analyzed data using one of potentially many approaches. We have already encountered the following methods that facilitate saving and loading data:\n",
    "\n",
    "* %pwd, %ls, %cd magic commands\n",
    "* !pwd, !ls, !cd shell commands\n",
    "* os module\n",
    "* %store magic command\n",
    "* NumPy save/savetxt and load/loadtxt/genfromtxt\n",
    "\n",
    "Today, we will explore several other methods:\n",
    "\n",
    "* glob module\n",
    "* Standard file input and output\n",
    "* csv reader\n",
    "* pickle and shelve modules\n",
    "* pandas methods\n",
    "\n",
    "In addition to today's topics, you may also want to explore Python's capability for interacting with other data types:\n",
    "\n",
    "* json module (JSON)\n",
    "* lxml (XML)\n",
    "* requests, urllib2 modules (HTML)\n",
    "* BeautifulSoup (HTML)\n",
    "* Excel files (pd.read_excel)\n",
    "* Database methods (sqlalchemy, pd.read_sql, sqlite3)\n",
    "* Web application programming interface (API) methods\n",
    "\n",
    "Friendly Reminders:\n",
    "\n",
    "* Homework #2 due tonight by 11:59 p.m.\n",
    "* Homework #3 released today, due March 5 by 11:59 p.m.\n",
    "* Project proposal due March 7 by 11:59 p.m."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## glob Module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **glob** module allows you to determine all of the file names on a particular path that match a particular pattern. The glob module offers two functions:\n",
    "\n",
    "* glob.glob(*pattern*) returns a list of file names that match *pattern*\n",
    "* glob.iglob(*pattern*) performs the same operation, but returns an iterator object instead (useful for many files)\n",
    "\n",
    "The pattern may consist of explicit characters for the directory path and file names, but also any combination of the following Unix-based special characters:\n",
    "\n",
    "* The asterisk ('*') matches text of any length\n",
    "* The question mark ('?') matches any single character\n",
    "* '[set]' matches any characters in the set\n",
    "* '[!set]' matches any characters not in the set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/charmain/Desktop/Master Degree/Term 2/Data Processing & Analysis in Python/Data Files\n"
     ]
    }
   ],
   "source": [
    "# Change current working directory to data folder\n",
    "%cd '/Users/charmain/Desktop/Master Degree/Term 2/Data Processing & Analysis in Python/Data Files/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['names/yob2000.txt',\n",
       " 'names/yob1938.txt',\n",
       " 'names/yob1910.txt',\n",
       " 'names/yob1904.txt',\n",
       " 'names/yob1905.txt']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract text files within names directory - glob\n",
    "name_files = glob.glob('names/*.txt') # unsorted by default\n",
    "name_files[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['names/yob2000.txt',\n",
       " 'names/yob2001.txt',\n",
       " 'names/yob2002.txt',\n",
       " 'names/yob2003.txt',\n",
       " 'names/yob2004.txt',\n",
       " 'names/yob2005.txt',\n",
       " 'names/yob2006.txt',\n",
       " 'names/yob2007.txt',\n",
       " 'names/yob2008.txt',\n",
       " 'names/yob2009.txt',\n",
       " 'names/yob2010.txt']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract text files within names directory - glob\n",
    "name_iter = glob.iglob('names/*.txt')\n",
    "sorted([f for f in name_iter if 'yob2' in f]) # use list comprehension to filter to 2000s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard File Input and Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python offers built-in functionality for reading from and writing to text files, which is useful for interacting with both structured and unstructured data. Everything that is read from or written to a file is a string, so you must using casting (e.g., cast numerical scalars using **str** to write to a file, cast strings to **int**, **float**, and **bool** when reading from a file) as needed.\n",
    "\n",
    "The basic syntax for interacting with file objects is:\n",
    "```\n",
    "f = open(fname, mode='r')\n",
    "```\n",
    "where *fname* is either a file name string ('data.txt') or a full path-to-file string ('~/Documents/data.txt') and *mode* is most commonly 'r' (read only), 'w' (write only), 'a' (append), or 'r+' (read and write). When writing to a new file, it's important to specify write mode so that the file has the appropriate permissions to write data to the file. It's also important to include the appropriate delimiter (if applicable) and the appropriate newline character for your respective operating system (see os.linesep)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.linesep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **open** function creates a file object, which has many attributes and methods for interacting with the file. The most notable methods are:\n",
    "\n",
    "* f.read(*size*) - Reads entire file as a string (if *size* is not specified), or a chunk of the file (equal to *size* in bytes)\n",
    "* f.readline() - Generator that produces one line of the file at a time\n",
    "* Loop!\n",
    "```\n",
    "for line in f:\n",
    "    print(line)\n",
    "```\n",
    "* f.write(*s*) - Write string _s_ to file\n",
    "* f.close() - Close file when done reading/writing\n",
    "\n",
    "It's important to note that once you reach of the end of the file, you cannot iterate through it again, unless you re-open the file or navigate to a specific place in the file using f.seek(*offset*), where *offset* is the location in the file where you want to move, relative to the beginning of the file (0 bytes). You can also use f.tell() to determine the current location (in bytes) in the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.TextIOWrapper name='names/yob2000.txt' mode='r' encoding='UTF-8'>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Open name file\n",
    "f = open(name_files[0]) # default is read only mode ('r')\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Emily,F,25949\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read line of file\n",
    "f.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hannah,F,23066\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print next line of file\n",
    "print(f.readline())   ## readline() will keep moving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check file position\n",
    "f.tell()             ## tell() could know what position we are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Emily,F,25949\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Go back to beginning of file\n",
    "f.seek(0)\n",
    "f.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Quinn', 'Quincy', 'Quiana', 'Queen', 'Quanisha', 'Quianna', 'Queenie', 'Qiana', 'Quinlan', 'Quiara', 'Quintasia', 'Quantaya', 'Quintessa', 'Quincey', 'Quyen', 'Quanesha', 'Quinci', 'Quinesha', 'Quinlyn', 'Qiara', 'Quincie', 'Quaneisha', 'Quasia', 'Quantasia', 'Quinisha', 'Quinteria', 'Quanique', 'Quierra', 'Quadasia', 'Quantavia', 'Quashia', 'Querida', 'Quintaya', 'Quynh', 'Quaniya', 'Quayla', 'Queena', 'Quetzalli', 'Qadira', 'Qianna', 'Quanae', 'Quetzali', 'Quiera', 'Quincee', 'Quinlin', 'Quinne', 'Quinnlyn', 'Quintara', 'Quintera', 'Quinterria', 'Quinn', 'Quentin', 'Quinton', 'Quincy', 'Quintin', 'Quinten', 'Quinlan', 'Quenton', 'Quran', 'Quadir', 'Quintavious', 'Quan', 'Quin', 'Quenten', 'Quincey', 'Quindarius', 'Qasim', 'Quest', 'Quade', 'Quamir', 'Quantavious', 'Quavon', 'Quadarius', 'Quantez', 'Quintez', 'Quaid', 'Quashawn', 'Quandarius', 'Quintyn', 'Quintan', 'Quang', 'Quante', 'Qadir', 'Quinnton', 'Quintarius', 'Quintrell', 'Quadre', 'Quashaun', 'Quantae', 'Quantavius', 'Quavion', 'Quintavius', 'Quamaine', 'Quron', 'Quartez', 'Quindarious', 'Quinterius', 'Quillan', 'Quaron', 'Quame', 'Quantavis', 'Quantrell', 'Quaylon', 'Quentyn', 'Quinlin', 'Quinnlan', 'Quoc', 'Quadrell', 'Qualin', 'Quantarius', 'Quashon', 'Quasim', 'Quason', 'Quendarius', 'Quentavious', 'Quevon', 'Quince', 'Quinshawn', 'Quintel', 'Quinterious', 'Quinterrius', 'Quishawn', 'Qamar', 'Qi', 'Quadarious', 'Quamere', 'Quashun', 'Qudarius', 'Que', 'Quess', 'Quienten', 'Quintavis', 'Quintell', 'Quion', 'Quisean', 'Qian', 'Quadere', 'Quameer', 'Quandre', 'Quantay', 'Quanterius', 'Quanterrious', 'Quatavious', 'Quayshawn', 'Quayvon', 'Quency', 'Quetzalcoatl', 'Quinell']\n"
     ]
    }
   ],
   "source": [
    "# Loop through file and extract all names that begin with a specific letter\n",
    "letter = 'Q'\n",
    "f.seek(0)\n",
    "names = []\n",
    "for line in f:\n",
    "    if line[0] == letter:\n",
    "        names.append(line.split(',')[0])\n",
    "f.close()    ## when we are done we close file, which is a good manner\n",
    "print(names)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open new file to write results\n",
    "g = open(letter + 'names.csv', 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through file and write names that begin with a specific letter, along with their length\n",
    "with open(name_files[0]) as f: # alternate construction for opening file, closes file upon exit from with statement\n",
    "    for line in f:\n",
    "        if line[0] == letter:\n",
    "            name = line.split(',')[0]\n",
    "            g.write(name + ',' + str(len(name)) + os.linesep)   \n",
    "g.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quinn,5\r\n",
      "Quincy,6\r\n",
      "Quiana,6\r\n",
      "Queen,5\r\n",
      "Quanisha,8\r\n",
      "Quianna,7\r\n",
      "Queenie,7\r\n",
      "Qiana,5\r\n",
      "Quinlan,7\r\n",
      "Quiara,6\r\n"
     ]
    }
   ],
   "source": [
    "# Preview file contents\n",
    "!head -n10 $g.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## csv Module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comma Separated Files (.csv) are one of the most common flat file formats for storing data, and are often output from common software platforms such as Microsoft Excel, various databases, or other programming languages. Commas are sufficient delimiters for structured numerical data (in the U.S.), but they can cause problems when working with data that may contain commas. In such cases, you should use another delimiter (e.g., space, tab; see csv.writer) that facilitates an easy import."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mary,F,7065\r",
      "\r\n",
      "Anna,F,2604\r",
      "\r\n",
      "Emma,F,2003\r",
      "\r\n",
      "Elizabeth,F,1939\r",
      "\r\n",
      "Minnie,F,1746\r",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!head -n5 names/yob1880.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **csv** module facilitates easy reading and writing to/from .csv files. The csv has two primary functions, csv.reader and csv.writer, that perform these functions. Each of these functions must be fed an open file handle (i.e., generated via an open(*filename*) call)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open file and create csv reader object\n",
    "f = open(name_files[0])     ## before we use csv reader or writter, we still need to open the file\n",
    "reader = csv.reader(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Unique', 'Uma', 'Ursula', 'Unknown', 'Uriah', 'Una', 'Ulyssa', 'Unity', 'Urvi', 'Ulani', 'Uchenna', 'Uniqua', 'Umayah', 'Uriel', 'Uyen', 'Uchechi', 'Uchechukwu', 'Ulyana', 'Unica', 'Ubah', 'Ugochi', 'Ula', 'Umaya', 'Urja', 'Urmi', 'Ushna', 'Uzma', 'Uriel', 'Ulises', 'Ulysses', 'Uriah', 'Ulisses', 'Umar', 'Uziel', 'Ulices', 'Ubaldo', 'Unknown', 'Unique', 'Ulyses', 'Usman', 'Usama', 'Uri', 'Usher', 'Uzziel', 'Umair', 'Umer', 'Urian', 'Usiel', 'Uchenna', 'Uday', 'Uzziah', 'Uvaldo', 'Uzair', 'Urias', 'Ugonna', 'Utah', 'Ulrich', 'Urbano', 'Uzoma', 'Ulisis', 'Ulysess', 'Umberto', 'Urban', 'Urijah', 'Urie', 'Usamah']\n"
     ]
    }
   ],
   "source": [
    "# Loop through file and extract all names that begin with a specific letter\n",
    "letter = 'U'\n",
    "names = []\n",
    "for line in reader:\n",
    "    if line[0][0] == letter:      ## line[0]: select the first word, then line[0][0] select the first letter of it\n",
    "        names.append(line[0])    ## csv does \"split\" for us\n",
    "f.close()\n",
    "print(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open file for writing and create csv writer object\n",
    "g = open(letter + 'names.csv', 'w')\n",
    "writer = csv.writer(g, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through file and extract all names that begin with a specific letter, along with their length\n",
    "for name in names:\n",
    "    writer.writerow((name, len(name)))   ## writerow(the sequence we want to show)\n",
    "g.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique,6\r",
      "\r\n",
      "Uma,3\r",
      "\r\n",
      "Ursula,6\r",
      "\r\n",
      "Unknown,7\r",
      "\r\n",
      "Uriah,5\r",
      "\r\n",
      "Una,3\r",
      "\r\n",
      "Ulyssa,6\r",
      "\r\n",
      "Unity,5\r",
      "\r\n",
      "Urvi,4\r",
      "\r\n",
      "Ulani,5\r",
      "\r\n"
     ]
    }
   ],
   "source": [
    "# Preview file contents\n",
    "!head -n10 $g.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pickle and shelve Modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to reading and writing data from/to files, you will also find it useful to directly save objects to a file, so that you can quickly load them without having to repeatedly convert them from text files. The pickle and shelve modules offer functionality for doing this:\n",
    "\n",
    "* The **pickle** module performs *object serialization*, through which a Python object is converted into a binary format that is saveable.\n",
    "\n",
    "* The **shelve** module performs *object persistence*, through which the object itself is preserved for later use in a dictionary-like structure (i.e., upon re-loading). The shelve module relies on the pickle module to save the objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle, shelve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open file in binary write mode for pickling\n",
    "f = open('name_list','bw') # pickle files do not need a file extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dump list of names to file and close file\n",
    "pickle.dump(names, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Unique', 'Uma', 'Ursula', 'Unknown', 'Uriah', 'Una', 'Ulyssa', 'Unity', 'Urvi', 'Ulani', 'Uchenna', 'Uniqua', 'Umayah', 'Uriel', 'Uyen', 'Uchechi', 'Uchechukwu', 'Ulyana', 'Unica', 'Ubah', 'Ugochi', 'Ula', 'Umaya', 'Urja', 'Urmi', 'Ushna', 'Uzma', 'Uriel', 'Ulises', 'Ulysses', 'Uriah', 'Ulisses', 'Umar', 'Uziel', 'Ulices', 'Ubaldo', 'Unknown', 'Unique', 'Ulyses', 'Usman', 'Usama', 'Uri', 'Usher', 'Uzziel', 'Umair', 'Umer', 'Urian', 'Usiel', 'Uchenna', 'Uday', 'Uzziah', 'Uvaldo', 'Uzair', 'Urias', 'Ugonna', 'Utah', 'Ulrich', 'Urbano', 'Uzoma', 'Ulisis', 'Ulysess', 'Umberto', 'Urban', 'Urijah', 'Urie', 'Usamah']\n"
     ]
    }
   ],
   "source": [
    "# Delete names and re-load from pickle file\n",
    "del names\n",
    "f = open('name_list','br')\n",
    "names = pickle.load(f)\n",
    "f.close()\n",
    "print(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<shelve.DbfilenameShelf at 0x10fba44a8>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Open shelve file for object persistence\n",
    "S = shelve.open('names_shelve') # or, with shelve.open('names_shelve') as S:\n",
    "S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add list of names to S and close file\n",
    "S['names'] = names   ## add keys for shelf file\n",
    "S.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Unique', 'Uma', 'Ursula', 'Unknown', 'Uriah', 'Una', 'Ulyssa', 'Unity', 'Urvi', 'Ulani', 'Uchenna', 'Uniqua', 'Umayah', 'Uriel', 'Uyen', 'Uchechi', 'Uchechukwu', 'Ulyana', 'Unica', 'Ubah', 'Ugochi', 'Ula', 'Umaya', 'Urja', 'Urmi', 'Ushna', 'Uzma', 'Uriel', 'Ulises', 'Ulysses', 'Uriah', 'Ulisses', 'Umar', 'Uziel', 'Ulices', 'Ubaldo', 'Unknown', 'Unique', 'Ulyses', 'Usman', 'Usama', 'Uri', 'Usher', 'Uzziel', 'Umair', 'Umer', 'Urian', 'Usiel', 'Uchenna', 'Uday', 'Uzziah', 'Uvaldo', 'Uzair', 'Urias', 'Ugonna', 'Utah', 'Ulrich', 'Urbano', 'Uzoma', 'Ulisis', 'Ulysess', 'Umberto', 'Urban', 'Urijah', 'Urie', 'Usamah']\n"
     ]
    }
   ],
   "source": [
    "# Delete list of names and re-load from shelve file\n",
    "del names\n",
    "with shelve.open('names_shelve') as S:\n",
    "    print(S['names'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pandas Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Being the primary module for data processing and analysis, it should not surprise you that there is a lot of functionality for interacting with various types of data sources. This functionality has grown significantly over the years, and will continue to grow as new file formats emerge.\n",
    "\n",
    "* pd.read_csv - Load delimited data from a file, URL, or file-like object\n",
    "* pd.read_table - Load delimited data from a file, URL, or file-like object\n",
    "* pd.read_fwf - Load data in fixed-width column format (non-delimited files)\n",
    "* pd.read_clipboard - Load data that is copied directly from another source (e.g., web page, Excel)\n",
    "* pd.read_excel - Load data directly from Excel file (without saving to .csv)\n",
    "* pd.read_html - Read tables found on a web page (URL) or within an HTML document\n",
    "* pd.read_json - Read data from a JSON (JavaScript Object Notation) file\n",
    "* pd.read_pickle - Read an objected stored in Python pickle format\n",
    "* pd.read_sas - Read a SAS dataset\n",
    "* pd.read_sql - Read the results of an SQL query into a DataFrame\n",
    "* pd.read_stata - Read a dataset from Stata file format\n",
    "\n",
    "And more! See Table 6-1 in the text for additional functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Text Data with pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pd.read_csv is the most common functions use to import data from text (flat) files. As there are many potential nuances to loading data from text files, there are many arguments to this function that can facilitate proper data loading (in addition to the file path/name):\n",
    "\n",
    "* sep, delimiter - String or regular expression to use to split the columns in each row\n",
    "* header - Row number to use as column names, use header=None if there is no header in the data\n",
    "* index_col - Column number(s) to use as index; multiple columns indicates hierarchical indexing\n",
    "* names - Sequence of column names for result, use with header=None\n",
    "* na_values - Sequence of values to replace with NA\n",
    "* parse_dates - Boolean to determine whether to attempt to parse data to datetime scalars; False by default\n",
    "* converters - Dictionary that specifies functions (values) to apply to specific columns (keys)\n",
    "* squeeze - Boolean that, if True, will convert DataFrame to Series if there is only one column\n",
    "\n",
    "In addition, there are several arguments that allow you read text files in pieces:\n",
    "\n",
    "* nrows - Number of rows to read from beginning of file\n",
    "* skiprows - Number of rows at beginning of file to ignore or list of specific row numbers to skip\n",
    "* skip_footer - Number of rows to ignore at end of file\n",
    "* chunksize - Creates iterator for looping through file in pieces; convenient for working with large files\n",
    "\n",
    "And more! See Table 6-2 in the text for additional arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Film</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Lead Studio</th>\n",
       "      <th>Audience  score %</th>\n",
       "      <th>Profitability</th>\n",
       "      <th>Rotten Tomatoes %</th>\n",
       "      <th>Worldwide Gross</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27 Dresses</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>Fox</td>\n",
       "      <td>71</td>\n",
       "      <td>5.343622</td>\n",
       "      <td>40</td>\n",
       "      <td>160.308654</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(500) Days of Summer</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>Fox</td>\n",
       "      <td>81</td>\n",
       "      <td>8.096000</td>\n",
       "      <td>87</td>\n",
       "      <td>60.720000</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A Dangerous Method</td>\n",
       "      <td>Drama</td>\n",
       "      <td>Independent</td>\n",
       "      <td>89</td>\n",
       "      <td>0.448645</td>\n",
       "      <td>79</td>\n",
       "      <td>8.972895</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A Serious Man</td>\n",
       "      <td>Drama</td>\n",
       "      <td>Universal</td>\n",
       "      <td>64</td>\n",
       "      <td>4.382857</td>\n",
       "      <td>89</td>\n",
       "      <td>30.680000</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Across the Universe</td>\n",
       "      <td>Romance</td>\n",
       "      <td>Independent</td>\n",
       "      <td>84</td>\n",
       "      <td>0.652603</td>\n",
       "      <td>54</td>\n",
       "      <td>29.367143</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Film    Genre  Lead Studio  Audience  score %  \\\n",
       "0            27 Dresses   Comedy          Fox                 71   \n",
       "1  (500) Days of Summer   Comedy          Fox                 81   \n",
       "2    A Dangerous Method    Drama  Independent                 89   \n",
       "3         A Serious Man    Drama    Universal                 64   \n",
       "4   Across the Universe  Romance  Independent                 84   \n",
       "\n",
       "   Profitability  Rotten Tomatoes %  Worldwide Gross  Year  \n",
       "0       5.343622                 40       160.308654  2008  \n",
       "1       8.096000                 87        60.720000  2009  \n",
       "2       0.448645                 79         8.972895  2011  \n",
       "3       4.382857                 89        30.680000  2009  \n",
       "4       0.652603                 54        29.367143  2007  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load movies data using pd.read_csv\n",
    "df = pd.read_csv('movies.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Film                  object\n",
       "Genre                 object\n",
       "Lead Studio           object\n",
       "Audience  score %      int64\n",
       "Profitability        float64\n",
       "Rotten Tomatoes %      int64\n",
       "Worldwide Gross      float64\n",
       "Year                   int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check dtypes\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Film', 'Genre', 'Lead Studio', 'Audience  score %', 'Profitability',\n",
       "       'Rotten Tomatoes %', 'Worldwide Gross', 'Year'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check column names\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Film</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Lead Studio</th>\n",
       "      <th>Audience  score %</th>\n",
       "      <th>Profitability</th>\n",
       "      <th>Rotten Tomatoes %</th>\n",
       "      <th>Worldwide Gross</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27 Dresses</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>Fox</td>\n",
       "      <td>71.0</td>\n",
       "      <td>5.343622</td>\n",
       "      <td>40.0</td>\n",
       "      <td>160.308654</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(500) Days of Summer</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>Fox</td>\n",
       "      <td>81.0</td>\n",
       "      <td>8.096000</td>\n",
       "      <td>87.0</td>\n",
       "      <td>60.720000</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A Dangerous Method</td>\n",
       "      <td>Drama</td>\n",
       "      <td>Independent</td>\n",
       "      <td>89.0</td>\n",
       "      <td>0.448645</td>\n",
       "      <td>79.0</td>\n",
       "      <td>8.972895</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A Serious Man</td>\n",
       "      <td>Drama</td>\n",
       "      <td>Universal</td>\n",
       "      <td>64.0</td>\n",
       "      <td>4.382857</td>\n",
       "      <td>89.0</td>\n",
       "      <td>30.680000</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Across the Universe</td>\n",
       "      <td>Romance</td>\n",
       "      <td>Independent</td>\n",
       "      <td>84.0</td>\n",
       "      <td>0.652603</td>\n",
       "      <td>54.0</td>\n",
       "      <td>29.367143</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Film    Genre  Lead Studio  Audience  score %  \\\n",
       "0            27 Dresses   Comedy          Fox               71.0   \n",
       "1  (500) Days of Summer   Comedy          Fox               81.0   \n",
       "2    A Dangerous Method    Drama  Independent               89.0   \n",
       "3         A Serious Man    Drama    Universal               64.0   \n",
       "4   Across the Universe  Romance  Independent               84.0   \n",
       "\n",
       "   Profitability  Rotten Tomatoes %  Worldwide Gross  Year  \n",
       "0       5.343622               40.0       160.308654  2008  \n",
       "1       8.096000               87.0        60.720000  2009  \n",
       "2       0.448645               79.0         8.972895  2011  \n",
       "3       4.382857               89.0        30.680000  2009  \n",
       "4       0.652603               54.0        29.367143  2007  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load movies data with dtype specifications\n",
    "df = pd.read_csv('movies.csv', dtype={'Audience  score %': np.float64, 'Rotten Tomatoes %': np.float64})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emily</th>\n",
       "      <th>F</th>\n",
       "      <th>25949</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hannah</td>\n",
       "      <td>F</td>\n",
       "      <td>23066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Madison</td>\n",
       "      <td>F</td>\n",
       "      <td>19965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ashley</td>\n",
       "      <td>F</td>\n",
       "      <td>17991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sarah</td>\n",
       "      <td>F</td>\n",
       "      <td>17677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alexis</td>\n",
       "      <td>F</td>\n",
       "      <td>17622</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Emily  F  25949\n",
       "0   Hannah  F  23066\n",
       "1  Madison  F  19965\n",
       "2   Ashley  F  17991\n",
       "3    Sarah  F  17677\n",
       "4   Alexis  F  17622"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing data without headers\n",
    "df = pd.read_csv(name_files[0])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Emily</td>\n",
       "      <td>F</td>\n",
       "      <td>25949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hannah</td>\n",
       "      <td>F</td>\n",
       "      <td>23066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Madison</td>\n",
       "      <td>F</td>\n",
       "      <td>19965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ashley</td>\n",
       "      <td>F</td>\n",
       "      <td>17991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sarah</td>\n",
       "      <td>F</td>\n",
       "      <td>17677</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0  1      2\n",
       "0    Emily  F  25949\n",
       "1   Hannah  F  23066\n",
       "2  Madison  F  19965\n",
       "3   Ashley  F  17991\n",
       "4    Sarah  F  17677"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing data without headers\n",
    "df = pd.read_csv(name_files[0], header=None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Emily</td>\n",
       "      <td>F</td>\n",
       "      <td>25949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hannah</td>\n",
       "      <td>F</td>\n",
       "      <td>23066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Madison</td>\n",
       "      <td>F</td>\n",
       "      <td>19965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ashley</td>\n",
       "      <td>F</td>\n",
       "      <td>17991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sarah</td>\n",
       "      <td>F</td>\n",
       "      <td>17677</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Name Gender  Count\n",
       "0    Emily      F  25949\n",
       "1   Hannah      F  23066\n",
       "2  Madison      F  19965\n",
       "3   Ashley      F  17991\n",
       "4    Sarah      F  17677"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing data without headers\n",
    "df = pd.read_csv(name_files[0], header=None, names=['Name','Gender','Count'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping Tabular Data from the Web with pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scraping tabular data from a web site (or raw HTML) is probably the next most common method for importing data into your Python workspace. In addition to pd.read_clipboard--which you may find useful for simple tables--the pd.read_html function is the standard pandas function for scraping tabular data from a website. This function takes in a URL (as a string), HTML file-like object, or raw HTML text (as a string), and returns a list of all found HTML tables.\n",
    "\n",
    "In addition to several of the same arguments that are available for the pd.read_csv function (e.g., header, index_col, skiprows, parse_dates, na_values, converters), there is also a *match* argument for which you can specify the exact table(s) that you want to return. The *match* argument could be an explicit string (e.g., substring, word, phrase) that you want to match (anywhere) within the table, or a regular expression (later).\n",
    "\n",
    "**Also, be warned, scraping data from a web site is a messy process! Oftentimes, we will need to perform significant processing on the data before it is ready for analysis.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team</th>\n",
       "      <th>2018</th>\n",
       "      <th>Last 3</th>\n",
       "      <th>Last 1</th>\n",
       "      <th>Home</th>\n",
       "      <th>Away</th>\n",
       "      <th>2017</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rank</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Golden State</td>\n",
       "      <td>118.8</td>\n",
       "      <td>114.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>118.6</td>\n",
       "      <td>112.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Milwaukee</td>\n",
       "      <td>116.9</td>\n",
       "      <td>100.3</td>\n",
       "      <td>106.0</td>\n",
       "      <td>119.6</td>\n",
       "      <td>114.3</td>\n",
       "      <td>106.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Philadelphia</td>\n",
       "      <td>115.9</td>\n",
       "      <td>126.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>119.1</td>\n",
       "      <td>112.5</td>\n",
       "      <td>109.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>New Orleans</td>\n",
       "      <td>115.6</td>\n",
       "      <td>103.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>116.8</td>\n",
       "      <td>114.5</td>\n",
       "      <td>111.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Okla City</td>\n",
       "      <td>115.4</td>\n",
       "      <td>119.7</td>\n",
       "      <td>122.0</td>\n",
       "      <td>116.3</td>\n",
       "      <td>114.6</td>\n",
       "      <td>107.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Toronto</td>\n",
       "      <td>114.3</td>\n",
       "      <td>120.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>115.8</td>\n",
       "      <td>112.9</td>\n",
       "      <td>111.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LA Clippers</td>\n",
       "      <td>114.3</td>\n",
       "      <td>125.7</td>\n",
       "      <td>134.0</td>\n",
       "      <td>116.2</td>\n",
       "      <td>112.5</td>\n",
       "      <td>109.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Washington</td>\n",
       "      <td>113.9</td>\n",
       "      <td>122.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>117.8</td>\n",
       "      <td>110.5</td>\n",
       "      <td>106.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sacramento</td>\n",
       "      <td>113.4</td>\n",
       "      <td>112.3</td>\n",
       "      <td>118.0</td>\n",
       "      <td>113.7</td>\n",
       "      <td>113.1</td>\n",
       "      <td>98.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Portland</td>\n",
       "      <td>113.3</td>\n",
       "      <td>113.7</td>\n",
       "      <td>129.0</td>\n",
       "      <td>116.7</td>\n",
       "      <td>109.0</td>\n",
       "      <td>105.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Houston</td>\n",
       "      <td>113.1</td>\n",
       "      <td>114.3</td>\n",
       "      <td>111.0</td>\n",
       "      <td>116.7</td>\n",
       "      <td>109.5</td>\n",
       "      <td>111.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Boston</td>\n",
       "      <td>113.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>115.7</td>\n",
       "      <td>109.9</td>\n",
       "      <td>103.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>San Antonio</td>\n",
       "      <td>112.3</td>\n",
       "      <td>110.3</td>\n",
       "      <td>108.0</td>\n",
       "      <td>113.9</td>\n",
       "      <td>110.9</td>\n",
       "      <td>102.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>112.3</td>\n",
       "      <td>126.3</td>\n",
       "      <td>148.0</td>\n",
       "      <td>114.9</td>\n",
       "      <td>109.6</td>\n",
       "      <td>106.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>LA Lakers</td>\n",
       "      <td>112.2</td>\n",
       "      <td>120.7</td>\n",
       "      <td>113.0</td>\n",
       "      <td>111.1</td>\n",
       "      <td>113.4</td>\n",
       "      <td>108.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Denver</td>\n",
       "      <td>112.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>116.1</td>\n",
       "      <td>107.7</td>\n",
       "      <td>110.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Minnesota</td>\n",
       "      <td>111.9</td>\n",
       "      <td>122.7</td>\n",
       "      <td>121.0</td>\n",
       "      <td>113.9</td>\n",
       "      <td>109.8</td>\n",
       "      <td>109.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Charlotte</td>\n",
       "      <td>110.8</td>\n",
       "      <td>102.7</td>\n",
       "      <td>89.0</td>\n",
       "      <td>113.2</td>\n",
       "      <td>108.4</td>\n",
       "      <td>108.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Atlanta</td>\n",
       "      <td>110.6</td>\n",
       "      <td>105.3</td>\n",
       "      <td>91.0</td>\n",
       "      <td>111.1</td>\n",
       "      <td>110.2</td>\n",
       "      <td>103.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Utah</td>\n",
       "      <td>109.2</td>\n",
       "      <td>116.3</td>\n",
       "      <td>108.0</td>\n",
       "      <td>111.3</td>\n",
       "      <td>107.2</td>\n",
       "      <td>103.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Dallas</td>\n",
       "      <td>108.7</td>\n",
       "      <td>102.3</td>\n",
       "      <td>101.0</td>\n",
       "      <td>110.4</td>\n",
       "      <td>107.0</td>\n",
       "      <td>102.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Indiana</td>\n",
       "      <td>108.1</td>\n",
       "      <td>100.3</td>\n",
       "      <td>97.0</td>\n",
       "      <td>107.9</td>\n",
       "      <td>108.4</td>\n",
       "      <td>105.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Detroit</td>\n",
       "      <td>106.6</td>\n",
       "      <td>117.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>108.4</td>\n",
       "      <td>104.4</td>\n",
       "      <td>103.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Phoenix</td>\n",
       "      <td>105.9</td>\n",
       "      <td>106.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>105.9</td>\n",
       "      <td>106.0</td>\n",
       "      <td>103.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Orlando</td>\n",
       "      <td>105.8</td>\n",
       "      <td>123.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>107.7</td>\n",
       "      <td>104.0</td>\n",
       "      <td>103.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>New York</td>\n",
       "      <td>105.3</td>\n",
       "      <td>107.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>105.3</td>\n",
       "      <td>105.3</td>\n",
       "      <td>104.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Miami</td>\n",
       "      <td>105.1</td>\n",
       "      <td>105.7</td>\n",
       "      <td>112.0</td>\n",
       "      <td>104.3</td>\n",
       "      <td>105.8</td>\n",
       "      <td>103.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Chicago</td>\n",
       "      <td>103.2</td>\n",
       "      <td>115.3</td>\n",
       "      <td>122.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>103.3</td>\n",
       "      <td>102.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Cleveland</td>\n",
       "      <td>103.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>104.1</td>\n",
       "      <td>101.8</td>\n",
       "      <td>108.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Memphis</td>\n",
       "      <td>100.6</td>\n",
       "      <td>105.3</td>\n",
       "      <td>110.0</td>\n",
       "      <td>100.9</td>\n",
       "      <td>100.3</td>\n",
       "      <td>99.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Team   2018  Last 3  Last 1   Home   Away   2017\n",
       "Rank                                                          \n",
       "1     Golden State  118.8   114.0   107.0  119.0  118.6  112.8\n",
       "2        Milwaukee  116.9   100.3   106.0  119.6  114.3  106.1\n",
       "3     Philadelphia  115.9   126.0   126.0  119.1  112.5  109.7\n",
       "4      New Orleans  115.6   103.0   131.0  116.8  114.5  111.5\n",
       "5        Okla City  115.4   119.7   122.0  116.3  114.6  107.4\n",
       "6          Toronto  114.3   120.0   129.0  115.8  112.9  111.2\n",
       "7      LA Clippers  114.3   125.7   134.0  116.2  112.5  109.0\n",
       "8       Washington  113.9   122.0   120.0  117.8  110.5  106.6\n",
       "9       Sacramento  113.4   112.3   118.0  113.7  113.1   98.8\n",
       "10        Portland  113.3   113.7   129.0  116.7  109.0  105.6\n",
       "11         Houston  113.1   114.3   111.0  116.7  109.5  111.1\n",
       "12          Boston  113.0   114.0   118.0  115.7  109.9  103.5\n",
       "13     San Antonio  112.3   110.3   108.0  113.9  110.9  102.4\n",
       "14        Brooklyn  112.3   126.3   148.0  114.9  109.6  106.6\n",
       "15       LA Lakers  112.2   120.7   113.0  111.1  113.4  108.1\n",
       "16          Denver  112.0   111.0   120.0  116.1  107.7  110.0\n",
       "17       Minnesota  111.9   122.7   121.0  113.9  109.8  109.1\n",
       "18       Charlotte  110.8   102.7    89.0  113.2  108.4  108.2\n",
       "19         Atlanta  110.6   105.3    91.0  111.1  110.2  103.4\n",
       "20            Utah  109.2   116.3   108.0  111.3  107.2  103.9\n",
       "21          Dallas  108.7   102.3   101.0  110.4  107.0  102.3\n",
       "22         Indiana  108.1   100.3    97.0  107.9  108.4  105.2\n",
       "23         Detroit  106.6   117.0   110.0  108.4  104.4  103.8\n",
       "24         Phoenix  105.9   106.0   107.0  105.9  106.0  103.9\n",
       "25         Orlando  105.8   123.0   127.0  107.7  104.0  103.4\n",
       "26        New York  105.3   107.0   106.0  105.3  105.3  104.5\n",
       "27           Miami  105.1   105.7   112.0  104.3  105.8  103.4\n",
       "28         Chicago  103.2   115.3   122.0  103.0  103.3  102.9\n",
       "29       Cleveland  103.0   112.0   139.0  104.1  101.8  108.8\n",
       "30         Memphis  100.6   105.3   110.0  100.9  100.3   99.3"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean HTML table\n",
    "url = 'https://www.teamrankings.com/nba/stat/points-per-game'\n",
    "df = pd.read_html(url, index_col=0)[0]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Team      Portland\n",
       "2018         113.3\n",
       "Last 3       113.7\n",
       "Last 1         129\n",
       "Home         116.7\n",
       "Away           109\n",
       "2017         105.6\n",
       "Name: 10, dtype: object"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Index specific ranked team\n",
    "df.loc[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multiple HTML tables\n",
    "url = 'https://www.basketball-reference.com/leagues/NBA_2018.html'\n",
    "dfs = pd.read_html(url, match='Conference')\n",
    "len(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Eastern Conference</th>\n",
       "      <th>W</th>\n",
       "      <th>L</th>\n",
       "      <th>W/L%</th>\n",
       "      <th>GB</th>\n",
       "      <th>PS/G</th>\n",
       "      <th>PA/G</th>\n",
       "      <th>SRS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Atlantic Division</td>\n",
       "      <td>Atlantic Division</td>\n",
       "      <td>Atlantic Division</td>\n",
       "      <td>Atlantic Division</td>\n",
       "      <td>Atlantic Division</td>\n",
       "      <td>Atlantic Division</td>\n",
       "      <td>Atlantic Division</td>\n",
       "      <td>Atlantic Division</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Toronto Raptors* (1)</td>\n",
       "      <td>59</td>\n",
       "      <td>23</td>\n",
       "      <td>.720</td>\n",
       "      <td>—</td>\n",
       "      <td>111.7</td>\n",
       "      <td>103.9</td>\n",
       "      <td>7.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Boston Celtics* (2)</td>\n",
       "      <td>55</td>\n",
       "      <td>27</td>\n",
       "      <td>.671</td>\n",
       "      <td>4.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>100.4</td>\n",
       "      <td>3.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Philadelphia 76ers* (3)</td>\n",
       "      <td>52</td>\n",
       "      <td>30</td>\n",
       "      <td>.634</td>\n",
       "      <td>7.0</td>\n",
       "      <td>109.8</td>\n",
       "      <td>105.3</td>\n",
       "      <td>4.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>New York Knicks (11)</td>\n",
       "      <td>29</td>\n",
       "      <td>53</td>\n",
       "      <td>.354</td>\n",
       "      <td>30.0</td>\n",
       "      <td>104.5</td>\n",
       "      <td>108.0</td>\n",
       "      <td>-3.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Brooklyn Nets (12)</td>\n",
       "      <td>28</td>\n",
       "      <td>54</td>\n",
       "      <td>.341</td>\n",
       "      <td>31.0</td>\n",
       "      <td>106.6</td>\n",
       "      <td>110.3</td>\n",
       "      <td>-3.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Central Division</td>\n",
       "      <td>Central Division</td>\n",
       "      <td>Central Division</td>\n",
       "      <td>Central Division</td>\n",
       "      <td>Central Division</td>\n",
       "      <td>Central Division</td>\n",
       "      <td>Central Division</td>\n",
       "      <td>Central Division</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Cleveland Cavaliers* (4)</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>.610</td>\n",
       "      <td>—</td>\n",
       "      <td>110.9</td>\n",
       "      <td>109.9</td>\n",
       "      <td>0.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Indiana Pacers* (5)</td>\n",
       "      <td>48</td>\n",
       "      <td>34</td>\n",
       "      <td>.585</td>\n",
       "      <td>2.0</td>\n",
       "      <td>105.6</td>\n",
       "      <td>104.2</td>\n",
       "      <td>1.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Milwaukee Bucks* (7)</td>\n",
       "      <td>44</td>\n",
       "      <td>38</td>\n",
       "      <td>.537</td>\n",
       "      <td>6.0</td>\n",
       "      <td>106.5</td>\n",
       "      <td>106.8</td>\n",
       "      <td>-0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Detroit Pistons (9)</td>\n",
       "      <td>39</td>\n",
       "      <td>43</td>\n",
       "      <td>.476</td>\n",
       "      <td>11.0</td>\n",
       "      <td>103.8</td>\n",
       "      <td>103.9</td>\n",
       "      <td>-0.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Chicago Bulls (13)</td>\n",
       "      <td>27</td>\n",
       "      <td>55</td>\n",
       "      <td>.329</td>\n",
       "      <td>23.0</td>\n",
       "      <td>102.9</td>\n",
       "      <td>110.0</td>\n",
       "      <td>-6.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Southeast Division</td>\n",
       "      <td>Southeast Division</td>\n",
       "      <td>Southeast Division</td>\n",
       "      <td>Southeast Division</td>\n",
       "      <td>Southeast Division</td>\n",
       "      <td>Southeast Division</td>\n",
       "      <td>Southeast Division</td>\n",
       "      <td>Southeast Division</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Miami Heat* (6)</td>\n",
       "      <td>44</td>\n",
       "      <td>38</td>\n",
       "      <td>.537</td>\n",
       "      <td>—</td>\n",
       "      <td>103.4</td>\n",
       "      <td>102.9</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Washington Wizards* (8)</td>\n",
       "      <td>43</td>\n",
       "      <td>39</td>\n",
       "      <td>.524</td>\n",
       "      <td>1.0</td>\n",
       "      <td>106.6</td>\n",
       "      <td>106.0</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Charlotte Hornets (10)</td>\n",
       "      <td>36</td>\n",
       "      <td>46</td>\n",
       "      <td>.439</td>\n",
       "      <td>8.0</td>\n",
       "      <td>108.2</td>\n",
       "      <td>108.0</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Orlando Magic (14)</td>\n",
       "      <td>25</td>\n",
       "      <td>57</td>\n",
       "      <td>.305</td>\n",
       "      <td>19.0</td>\n",
       "      <td>103.4</td>\n",
       "      <td>108.2</td>\n",
       "      <td>-4.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Atlanta Hawks (15)</td>\n",
       "      <td>24</td>\n",
       "      <td>58</td>\n",
       "      <td>.293</td>\n",
       "      <td>20.0</td>\n",
       "      <td>103.4</td>\n",
       "      <td>108.8</td>\n",
       "      <td>-5.30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Eastern Conference                   W                   L  \\\n",
       "0          Atlantic Division   Atlantic Division   Atlantic Division   \n",
       "1       Toronto Raptors* (1)                  59                  23   \n",
       "2        Boston Celtics* (2)                  55                  27   \n",
       "3    Philadelphia 76ers* (3)                  52                  30   \n",
       "4       New York Knicks (11)                  29                  53   \n",
       "5         Brooklyn Nets (12)                  28                  54   \n",
       "6           Central Division    Central Division    Central Division   \n",
       "7   Cleveland Cavaliers* (4)                  50                  32   \n",
       "8        Indiana Pacers* (5)                  48                  34   \n",
       "9       Milwaukee Bucks* (7)                  44                  38   \n",
       "10       Detroit Pistons (9)                  39                  43   \n",
       "11        Chicago Bulls (13)                  27                  55   \n",
       "12        Southeast Division  Southeast Division  Southeast Division   \n",
       "13           Miami Heat* (6)                  44                  38   \n",
       "14   Washington Wizards* (8)                  43                  39   \n",
       "15    Charlotte Hornets (10)                  36                  46   \n",
       "16        Orlando Magic (14)                  25                  57   \n",
       "17        Atlanta Hawks (15)                  24                  58   \n",
       "\n",
       "                  W/L%                  GB                PS/G  \\\n",
       "0    Atlantic Division   Atlantic Division   Atlantic Division   \n",
       "1                 .720                   —               111.7   \n",
       "2                 .671                 4.0               104.0   \n",
       "3                 .634                 7.0               109.8   \n",
       "4                 .354                30.0               104.5   \n",
       "5                 .341                31.0               106.6   \n",
       "6     Central Division    Central Division    Central Division   \n",
       "7                 .610                   —               110.9   \n",
       "8                 .585                 2.0               105.6   \n",
       "9                 .537                 6.0               106.5   \n",
       "10                .476                11.0               103.8   \n",
       "11                .329                23.0               102.9   \n",
       "12  Southeast Division  Southeast Division  Southeast Division   \n",
       "13                .537                   —               103.4   \n",
       "14                .524                 1.0               106.6   \n",
       "15                .439                 8.0               108.2   \n",
       "16                .305                19.0               103.4   \n",
       "17                .293                20.0               103.4   \n",
       "\n",
       "                  PA/G                 SRS  \n",
       "0    Atlantic Division   Atlantic Division  \n",
       "1                103.9                7.29  \n",
       "2                100.4                3.23  \n",
       "3                105.3                4.30  \n",
       "4                108.0               -3.53  \n",
       "5                110.3               -3.67  \n",
       "6     Central Division    Central Division  \n",
       "7                109.9                0.59  \n",
       "8                104.2                1.18  \n",
       "9                106.8               -0.45  \n",
       "10               103.9               -0.26  \n",
       "11               110.0               -6.84  \n",
       "12  Southeast Division  Southeast Division  \n",
       "13               102.9                0.15  \n",
       "14               106.0                0.53  \n",
       "15               108.0                0.07  \n",
       "16               108.2               -4.92  \n",
       "17               108.8               -5.30  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show specific table\n",
    "dfs[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing Data with pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Writing data from pandas data structures to a file is very straightforward. There are corresponding pandas functions to output Series and DataFrame objects to most of the file types that have read functions. A summary table is provided below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_html('https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html')[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each file type has its own distinct set of arguments that allow you to configure how the data is saved to the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output NBA team scoring data to .csv file\n",
    "df.to_csv('nba_scoring2019.csv', columns=['Team','2018','Home','Away'], header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Time: pandas Lab"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
